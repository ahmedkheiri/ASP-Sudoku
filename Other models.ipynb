{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, make_scorer, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible values: SA, RR, RVNS, SD or None\n",
    "\n",
    "- Using 'liblinear' solver - problem is decomposed to a \"one-vs-rest\" problem. And individual binary classifiers are trained.\n",
    "- 'saga' is better for sparse multinomial regression.\n",
    "\n",
    "Evaluation metrics (\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#precision-recall-f-measure-metrics )\n",
    "\n",
    "- Note that if all labels are included, “micro”-averaging in a multiclass setting will produce precision, recall and F1 that are all identical to accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsSummary = pd.read_pickle('./Data/Performance Data/resultsSummary.pkl')\n",
    "features = pd.read_csv('./Data/features.csv').drop(columns=['puzzles', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SA_SR</th>\n",
       "      <th>RR_SR</th>\n",
       "      <th>RVNS_SR</th>\n",
       "      <th>SD_SR</th>\n",
       "      <th>SA_meanCT</th>\n",
       "      <th>RR_meanCT</th>\n",
       "      <th>RVNS_meanCT</th>\n",
       "      <th>SD_meanCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.088150</td>\n",
       "      <td>0.08595</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>2.201569</td>\n",
       "      <td>2.084878</td>\n",
       "      <td>2.679376</td>\n",
       "      <td>2.775323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204289</td>\n",
       "      <td>0.20162</td>\n",
       "      <td>0.184411</td>\n",
       "      <td>0.179815</td>\n",
       "      <td>0.491848</td>\n",
       "      <td>0.458560</td>\n",
       "      <td>0.611188</td>\n",
       "      <td>0.628236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059631</td>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.002653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.185729</td>\n",
       "      <td>2.081912</td>\n",
       "      <td>2.481429</td>\n",
       "      <td>2.563323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.274711</td>\n",
       "      <td>2.160078</td>\n",
       "      <td>2.726923</td>\n",
       "      <td>2.814924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2.390130</td>\n",
       "      <td>2.253337</td>\n",
       "      <td>2.980403</td>\n",
       "      <td>3.114227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.462554</td>\n",
       "      <td>3.209921</td>\n",
       "      <td>4.155690</td>\n",
       "      <td>4.619463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SA_SR       RR_SR      RVNS_SR        SD_SR    SA_meanCT  \\\n",
       "count  1000.000000  1000.00000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.088150     0.08595     0.062100     0.058150     2.201569   \n",
       "std       0.204289     0.20162     0.184411     0.179815     0.491848   \n",
       "min       0.000000     0.00000     0.000000     0.000000     0.059631   \n",
       "25%       0.000000     0.00000     0.000000     0.000000     2.185729   \n",
       "50%       0.000000     0.00000     0.000000     0.000000     2.274711   \n",
       "75%       0.100000     0.10000     0.050000     0.050000     2.390130   \n",
       "max       1.000000     1.00000     1.000000     1.000000     3.462554   \n",
       "\n",
       "         RR_meanCT  RVNS_meanCT    SD_meanCT  \n",
       "count  1000.000000  1000.000000  1000.000000  \n",
       "mean      2.084878     2.679376     2.775323  \n",
       "std       0.458560     0.611188     0.628236  \n",
       "min       0.019630     0.008300     0.002653  \n",
       "25%       2.081912     2.481429     2.563323  \n",
       "50%       2.160078     2.726923     2.814924  \n",
       "75%       2.253337     2.980403     3.114227  \n",
       "max       3.209921     4.155690     4.619463  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsSummary[['SA_SR', 'RR_SR', 'RVNS_SR', 'SD_SR',\n",
    "                'SA_meanCT', 'RR_meanCT', 'RVNS_meanCT', 'SD_meanCT']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_all = list(features.columns)\n",
    "X_full = StandardScaler().fit_transform(features.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual best algorithm in terms of success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame()\n",
    "\n",
    "#actual best algorithm in terms of SR\n",
    "Y['SR_max'] = resultsSummary[['SA_SR', 'RR_SR', 'RVNS_SR', 'SD_SR']].max(axis='columns')\n",
    "\n",
    "SR_counts = {}\n",
    "for alg in ['SA_SR', 'RR_SR', 'RVNS_SR', 'SD_SR']:\n",
    "    SR_counts[alg] = [list(resultsSummary[alg])[i]== list(Y['SR_max'])[i] for i in range(1000)]\n",
    "\n",
    "Y['SR_ties_count'] = pd.DataFrame(SR_counts).sum(axis='columns').values\n",
    "Y['SR_best'] = resultsSummary[['SA_SR', 'RR_SR', 'RVNS_SR', 'SD_SR']].idxmax(axis='columns')\n",
    "\n",
    "#handling 3-way ties\n",
    "Y['SR_best'] = Y.apply(lambda x: 'None' if x.SR_ties_count>2 else x.SR_best,\n",
    "                       axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None       406\n",
       "SA_SR      275\n",
       "RR_SR      197\n",
       "RVNS_SR     70\n",
       "SD_SR       52\n",
       "Name: SR_best, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['SR_best'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual best performance in terms of mean cost-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y['CT_min'] = resultsSummary[[ 'RR_meanCT', 'SA_meanCT','RVNS_meanCT', 'SD_meanCT']].min(axis='columns')\n",
    "\n",
    "CT_counts = {}\n",
    "for alg in ['RR_meanCT','SA_meanCT',  'RVNS_meanCT', 'SD_meanCT']:\n",
    "    CT_counts[alg] = [np.abs(list(resultsSummary[alg])[i]- list(Y['CT_min'])[i])<10e-4 for i in range(1000)]\n",
    "\n",
    "Y['CT_ties_count'] = pd.DataFrame(CT_counts).sum(axis='columns').values\n",
    "Y['CT_best'] = resultsSummary[['SA_meanCT', 'RR_meanCT', 'RVNS_meanCT', 'SD_meanCT']].idxmin(axis='columns')\n",
    "\n",
    "#handling 3-way ties\n",
    "Y['CT_best'] = Y.apply(lambda x: 'None' if x.CT_ties_count>2 else x.CT_best,\n",
    "                       axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RR_meanCT      783\n",
       "SA_meanCT      172\n",
       "RVNS_meanCT     30\n",
       "SD_meanCT       15\n",
       "Name: CT_best, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['CT_best'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning and training multinomial logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegModelMul(X,Y,Yhat, mod,avg,sol = 'saga',maxit=5000):\n",
    "\n",
    "    y = Y[mod]\n",
    "\n",
    "    # finding best C for regularisation\n",
    "    lgc = LogisticRegressionCV(Cs=20,penalty='l1',solver=sol, max_iter=maxit,\n",
    "        cv=StratifiedKFold(5,shuffle=True,random_state=111),random_state=111).fit(X,y)\n",
    "\n",
    "    C_best = lgc.C_[0]\n",
    "\n",
    "\n",
    "    lg = LogisticRegression(penalty='l1',C=C_best,solver=sol,random_state=111,max_iter=maxit).fit(X,y)\n",
    "\n",
    "\n",
    "    metrics = {'accuracy':make_scorer(accuracy_score),\n",
    "        #'confusion': make_scorer(confusion_matrix,labels=['SA','RR','None'],normalize='all'),\n",
    "        'precision': make_scorer(precision_score,zero_division=1,average=avg),\n",
    "        'recall':make_scorer(recall_score,zero_division=1,average=avg),\n",
    "        'f1':make_scorer(f1_score,zero_division=1,average=avg)}\n",
    "    scores = cross_validate(lg, X_full, y,scoring=metrics,cv=10)\n",
    "    avgScores = {m: np.mean(scores['test_'+m]) for m in metrics}\n",
    "\n",
    "\n",
    "    selFeats = {feat_all[i]: lg.coef_[0][i] for i in range(54) if lg.coef_[0][i] != 0}\n",
    "\n",
    "\n",
    "    Yhat[mod] = lg.predict(X)\n",
    "\n",
    "    return C_best, avgScores, selFeats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat = pd.DataFrame()\n",
    "ScoresSel = dict()\n",
    "CsSel = dict()\n",
    "FeatsSel = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_best\n",
      "CT_best\n"
     ]
    }
   ],
   "source": [
    "for mod in ['SR_best','CT_best']:\n",
    "    print(mod)\n",
    "    CsSel[mod], ScoresSel[mod], FeatsSel[mod] = LogRegModelMul(X_full,Y,Yhat,mod,avg='weighted',sol='saga',maxit=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoresSelTable = pd.DataFrame(ScoresSel.values(),index=ScoresSel.keys())\n",
    "ScoresSelTable = ScoresSelTable*100\n",
    "#ScoresSelTable['ind'] = ScoresSelTable.index\n",
    "ScoresSelTable.insert(0,'feat',[len(x) for x in FeatsSel.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SR_best</th>\n",
       "      <th>CT_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>50.700000</td>\n",
       "      <td>78.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>62.881735</td>\n",
       "      <td>83.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>50.700000</td>\n",
       "      <td>78.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>37.812224</td>\n",
       "      <td>68.771238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SR_best    CT_best\n",
       "feat       10.000000   0.000000\n",
       "accuracy   50.700000  78.300000\n",
       "precision  62.881735  83.011000\n",
       "recall     50.700000  78.300000\n",
       "f1         37.812224  68.771238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ScoresSelTable.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None     658\n",
       "SA_SR    338\n",
       "RR_SR      4\n",
       "Name: SR_best, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yhat['SR_best'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C and features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SR_best': 0.08858667904100823, 'CT_best': 0.0001}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CsSel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fixedDig_min', 'fixedDig_entropy', 'counts_naked1', 'counts_naked2', 'counts_CV', 'counts_min', 'value_min', 'LPslack_entropy', 'GCP_nDeg_mean', 'GCP_nDeg_std'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatsSel['SR_best'].keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small C selected for CT model, so no features with non-zero coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatsSel['CT_best']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d514ac4aa0da024bf148ec1dbb2fd9f2753f39ee77232f5ea27ce0c7c626aa34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
